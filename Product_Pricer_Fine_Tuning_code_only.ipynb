{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c4e7faeb-5839-4499-ba1d-83b69dcf9fdc",
   "metadata": {},
   "source": [
    "# The Product Pricer Continued\n",
    "\n",
    "A model that can estimate how much something costs, from its description.\n",
    "\n",
    "## AT LAST - it's time for Fine Tuning!\n",
    "\n",
    "After all this data preparation, and old school machine learning, we've finally arrived at the moment you've been waiting for. Fine-tuning a model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d8f8f2ff-28af-4711-a1ef-177156d2368c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import os\n",
    "import re\n",
    "import math\n",
    "import json\n",
    "import random\n",
    "from dotenv import load_dotenv\n",
    "from huggingface_hub import login\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pickle\n",
    "from collections import Counter\n",
    "from openai import OpenAI\n",
    "from anthropic import Anthropic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "05dd28b2-4fd5-462f-b17d-30b6d072c161",
   "metadata": {},
   "outputs": [],
   "source": [
    "# environment\n",
    "\n",
    "load_dotenv(override=True)\n",
    "os.environ['OPENAI_API_KEY'] = os.getenv('OPENAI_API_KEY', 'your-key-if-not-using-env')\n",
    "os.environ['ANTHROPIC_API_KEY'] = os.getenv('ANTHROPIC_API_KEY', 'your-key-if-not-using-env')\n",
    "os.environ['HF_TOKEN'] = os.getenv('HF_TOKEN', 'your-key-if-not-using-env')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f34ac704-7310-4e52-9f69-13a30920b10f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log in to HuggingFace\n",
    "\n",
    "hf_token = os.environ['HF_TOKEN']\n",
    "login(hf_token, add_to_git_credential=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2bed4bb4-efe8-498d-b707-29fa290cb631",
   "metadata": {},
   "outputs": [],
   "source": [
    "# moved our Tester into a separate package\n",
    "# call it with Tester.test(function_name, test_dataset)\n",
    "\n",
    "from items import Item\n",
    "from testing import Tester"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "912139a0-415e-4892-83c5-a57eed9de917",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8085d4d5-6b3e-4d0b-a999-589f67703297",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "69c3d425-8df8-4975-a919-b342f8d38d17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's avoid curating all our data again! Load in the pickle files:\n",
    "\n",
    "with open('train.pkl', 'rb') as file:\n",
    "    train = pickle.load(file)\n",
    "\n",
    "with open('test.pkl', 'rb') as file:\n",
    "    test = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "19a62a90-f6f2-42fd-9c8d-adba4069e82e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OpenAI recommends fine-tuning with populations of 50-100 examples\n",
    "# But as our examples are very small, I'm suggesting we go with 200 examples (and 1 epoch)\n",
    "\n",
    "fine_tune_train = train[:200]\n",
    "fine_tune_validation = train[200:250]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc654d62-fe2d-4055-9fd7-bfc4b48ee2e5",
   "metadata": {},
   "source": [
    "# Step 1\n",
    "\n",
    "Prepare our data for fine-tuning in JSONL (JSON Lines) format and upload to OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e2ef98b4-fdd7-4070-877f-7f704e2ced0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First let's work on a good prompt for a Frontier model\n",
    "# When we train our own models, we'll need to make the problem as easy as possible, \n",
    "# but a Frontier model needs no such simplification.\n",
    "\n",
    "def messages_for(item):\n",
    "    system_message = \"You estimate prices of items. Reply only with the price, no explanation\"\n",
    "    user_prompt = item.test_prompt().replace(\" to the nearest dollar\",\"\").replace(\"\\n\\nPrice is $\",\"\")\n",
    "    return [\n",
    "        {\"role\": \"system\", \"content\": system_message},\n",
    "        {\"role\": \"user\", \"content\": user_prompt},\n",
    "        {\"role\": \"assistant\", \"content\": f\"Price is ${item.price:.2f}\"}\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0784a750-d0eb-4c45-a60c-bfb47a4cbb3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages_for(train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "abe066b3-284f-41a9-ab8c-edd65562e8c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the items into a list of json objects - a \"jsonl\" string\n",
    "# Each row represents a message in the form:\n",
    "# {\"messages\" : [{\"role\": \"system\", \"content\": \"You estimate prices...\n",
    "\n",
    "\n",
    "def make_jsonl(items):\n",
    "    result = \"\"\n",
    "    for item in items:\n",
    "        messages = messages_for(item)\n",
    "        messages_str = json.dumps(messages)                     # json.dumps converts to strings of messages\n",
    "        result += '{\"messages\": ' + messages_str +'}\\n'\n",
    "    return result.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a1c0db4f-e9d0-4641-acb9-760135dbe428",
   "metadata": {},
   "outputs": [],
   "source": [
    "# See string for first 3 training messages\n",
    "print(make_jsonl(train[:3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "40f7a468-1e55-4b61-a102-812c22300a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the items into jsonl and write them to a file\n",
    "\n",
    "def write_jsonl(items, filename):\n",
    "    with open(filename, \"w\") as f:\n",
    "        jsonl = make_jsonl(items)\n",
    "        f.write(jsonl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "32ca09b7-f25a-4463-a09f-6cdbbbf76274",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take file name and items, and calls function above\n",
    "\n",
    "write_jsonl(fine_tune_train, \"fine_tune_train.jsonl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "41e7eb49-6f9a-43ad-a751-b503cbcedac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_jsonl(fine_tune_validation, \"fine_tune_validation.jsonl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ba9bd0e7-c8ae-412b-8416-c7b00ea7f176",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload files to openAI using upload.files.create function. When you pass in - pass as 'rb' as binary files\n",
    "\n",
    "with open(\"fine_tune_train.jsonl\", \"rb\") as f:\n",
    "    train_file = openai.files.create(file=f, purpose=\"fine-tune\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "df3edfbc-5867-4e56-b6dc-f8d6e888afc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To check what came back for training set\n",
    "train_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "550389c6-0796-4ea0-89c2-dabb65f2fe6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"fine_tune_validation.jsonl\", \"rb\") as f:\n",
    "    validation_file = openai.files.create(file=f, purpose=\"fine-tune\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "92298bdd-0dfe-4e2b-8dd1-db3776b501b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To check what came back for validation set\n",
    "\n",
    "validation_file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c22a03fe-63c7-4eea-a4e8-5431823c7ba7",
   "metadata": {},
   "source": [
    "# Step 2\n",
    "\n",
    "I love Weights and Biases - a beautiful, free platform for monitoring training runs.  \n",
    "Weights and Biases is integrated with OpenAI for fine-tuning.\n",
    "\n",
    "First set up your weights & biases free account at:\n",
    "\n",
    "https://wandb.ai\n",
    "\n",
    "From the Avatar >> Settings menu, near the bottom, you can create an API key.\n",
    "\n",
    "Then visit the OpenAI dashboard at:\n",
    "\n",
    "https://platform.openai.com/account/organization\n",
    "\n",
    "In the integrations section, you can add your Weights & Biases key.\n",
    "\n",
    "## And now time to Fine-tune!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "17aec0ea-3a4a-4c16-84b7-7bc6ad798480",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up weights & bias integration, and giving a name \"gpt-pricer\"\n",
    "\n",
    "wandb_integration = {\"type\": \"wandb\", \"wandb\": {\"project\": \"gpt-pricer\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5790b456-df46-464d-ab2a-e3bd99bb99d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file.id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2e433080-734f-4768-a887-2b7649331757",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fine tune model by calling new OpenAI API - openai.fine_tuning.jobs.create function \n",
    "\n",
    "openai.fine_tuning.jobs.create(\n",
    "    training_file=train_file.id,\n",
    "    validation_file=validation_file.id,\n",
    "    model=\"gpt-4o-mini-2024-07-18\",\n",
    "    seed=42,\n",
    "    hyperparameters={\"n_epochs\": 1},\n",
    "    integrations = [wandb_integration],\n",
    "    suffix=\"pricer\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "8d952a78-a60a-427f-922c-f609e42376d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.fine_tuning.jobs.list(limit=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "352197a5-d8d3-40ee-9c0d-5476b071a0fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a variable job_id for our current run, so you dont need to remember\n",
    "\n",
    "job_id = openai.fine_tuning.jobs.list(limit=1).data[0].id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "44ae47a8-b160-44f4-8966-1a44cd106191",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "529818be-f0ba-4bca-a67b-8efd9e6228e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.fine_tuning.jobs.retrieve(job_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "db709369-df1b-4046-9e4c-e7529efda429",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.fine_tuning.jobs.list_events(fine_tuning_job_id=job_id, limit=10).data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baf0660b-e9c3-4da4-a93a-7299bd724d22",
   "metadata": {},
   "source": [
    "# Step 3\n",
    "\n",
    "Test our fine tuned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "f1fd1bfa-a641-4342-952b-6c4ec71a4eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "fine_tuned_model_name = openai.fine_tuning.jobs.retrieve(job_id).fine_tuned_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "47c0cc7d-bfd5-4257-96ea-3e539bc832fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "fine_tuned_model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "f5afaadc-328d-4d7a-9f61-b4f8ec98ee6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The prompt\n",
    "\n",
    "def messages_for(item):\n",
    "    system_message = \"You estimate prices of items. Reply only with the price, no explanation\"\n",
    "    user_prompt = item.test_prompt().replace(\" to the nearest dollar\",\"\").replace(\"\\n\\nPrice is $\",\"\")\n",
    "    return [\n",
    "        {\"role\": \"system\", \"content\": system_message},\n",
    "        {\"role\": \"user\", \"content\": user_prompt},\n",
    "        {\"role\": \"assistant\", \"content\": \"Price is $\"}\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "49f4d068-82c8-44d7-9341-e7c1bf921787",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try this out\n",
    "\n",
    "messages_for(test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "c7223681-839c-4e24-8fd4-302b3fedacf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A utility function to extract the price from a string\n",
    "\n",
    "def get_price(s):\n",
    "    s = s.replace('$','').replace(',','')\n",
    "    match = re.search(r\"[-+]?\\d*\\.\\d+|\\d+\", s)\n",
    "    return float(match.group()) if match else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "cbe18a8f-e369-42fc-8778-0eb37cf57b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_price(\"The price is roughly $99.99 because blah blah\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "15b88fa4-188a-4be8-9542-bd9927ed981a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The function for gpt-4o-mini\n",
    "\n",
    "def gpt_fine_tuned(item):\n",
    "    response = openai.chat.completions.create(\n",
    "        model=fine_tuned_model_name, \n",
    "        messages=messages_for(item),\n",
    "        seed=42,\n",
    "        max_tokens=7\n",
    "    )\n",
    "    reply = response.choices[0].message.content\n",
    "    return get_price(reply)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "79d02ca3-b751-4ab3-beb5-f40b28323cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test[0].price)\n",
    "print(gpt_fine_tuned(test[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "1e46b937-6ed5-45dc-b030-edb70595e922",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test[0].test_prompt())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "697ccf3b-917b-4904-802e-4242bf6ed330",
   "metadata": {},
   "outputs": [],
   "source": [
    "Tester.test(gpt_fine_tuned, test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
